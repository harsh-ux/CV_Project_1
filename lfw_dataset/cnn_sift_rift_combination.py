# -*- coding: utf-8 -*-
"""cnn_sift_rift_combination.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1crKb6MpfewKbkMY8gD41K_zcxcN_tCts

#CNN_SIFT_RITF
"""

import numpy as np
import pandas as pd 
from sklearn.model_selection import train_test_split

import cv2

import matplotlib.pyplot as plt
from tensorflow.keras.applications.vgg16 import VGG16
from datetime import datetime
import io
import itertools
from packaging import version



from tensorflow.keras import backend as K
import matplotlib.pyplot as plt
import numpy as np

import sklearn.metrics
from tensorflow.keras.optimizers import SGD
from sklearn.svm import LinearSVC
from sklearn.feature_selection import RFE

def normalize_mean_var(arr):
    arr -= np.mean(arr)
    arr /= np.var(arr)
    return arr

ritf_hist_train_path = "/content/RITF_hist_reduced_128_train_imc_50.npy"
ritf_hist_valid_path = "/content/RITF_hist_reduced_128_valid_imc_50.npy"

X_training_hists_reduced = np.load(ritf_hist_train_path)
X_valid_hists_reduced = np.load(ritf_hist_valid_path)

y_train_path = "/content/y_train_imc_50.npy"
y_valid_path = "/content/y_valid_imc_50.npy"

y_training = np.load(y_train_path)
y_validation = np.load(y_valid_path)

training_data_sift_hist = np.load('/content/sift_hist_50m_4k_training.npy')
valid_data_sift_hist = np.load('/content/sift_hist_50m_4k_validation.npy')

cnn_train_path = "/content/cnn_train_imc_50.npy"
cnn_valid_path = "/content/cnn_valid_imc_50.npy"


cnn_train = np.load(cnn_train_path)
cnn_valid = np.load(cnn_valid_path)

def norm_merge(arr1, arr2, alpha):
    a = normalize_mean_var(arr1.astype(np.float32)) * alpha
    b = normalize_mean_var(arr2.astype(np.float32)) * (1-alpha)
    return np.hstack((a, b))

training_data_SR = norm_merge(X_training_hists_reduced, training_data_sift_hist, 0.42)
validation_data_SR = norm_merge(X_valid_hists_reduced, valid_data_sift_hist, 0.42)

training_data = norm_merge(training_data_SR, cnn_train, 0.45)
validation_data = norm_merge(validation_data_SR, cnn_valid, 0.45)

def Linear_SVM_classification(X_train, X_test, y_train, y_test):
    #LinearSVC
    from sklearn.svm import LinearSVC

    svc= LinearSVC(C=100.0, random_state=1, max_iter=1000, verbose=1)
    svc.fit(X_train, y_train)

    svcpred = svc.predict(X_test)
    cnf_matrix = metrics.confusion_matrix(y_test, svcpred)
    SVC_acc = metrics.accuracy_score(y_test, svcpred)

    print('Linear SVC accuracy: {}'.format(SVC_acc))
    return SVC_acc

Linear_SVM_classification(cnn_train, cnn_valid, y_training, y_validation)

Linear_SVM_classification(cnn_train, cnn_valid, y_training, y_validation)

Linear_SVM_classification(training_data_SR, validation_data_SR, y_training, y_validation)

results = []
for i in range(1, 21):
    alpha = i / 100
    print("alpha = ", alpha)
    training_data = norm_merge(cnn_train, training_data_SR, alpha)
    validation_data = norm_merge(cnn_valid, validation_data_SR, alpha)
    acc = Linear_SVM_classification(training_data, validation_data, y_training, y_validation)
    results.append(acc)

import matplotlib.pyplot as plt

def show_plot(x_data, y_data, x_label, y_label, title):
    plt.subplots(figsize=(12*2, 12))
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.plot(x_data, y_data)
    plt.title(title)
    plt.show()

show_plot([i/100 for i in range(1, 21)], results, 'Alpha', 'Accuracy', 'Accuracy-Alpha')

def get_max_alpha(arr):
    max_a = 0
    max_acc = 0
    for i, acc in enumerate(arr):
        if acc > max_acc:
            max_a = (i+1) / 100
            max_acc = acc
    return max_a, max_acc

alp_acc = get_max_alpha(results)

alpha = 0.01
training_data = norm_merge(cnn_train, training_data_SR, alpha)
validation_data = norm_merge(cnn_valid, validation_data_SR, alpha)
acc = Linear_SVM_classification(training_data, validation_data, y_training, y_validation)

training_data.shape[1]

def get_selected_features(dataArr, trueValues):
    res = []
    for i, v in enumerate(dataArr):
        if trueValues[i]:
            res.append(v)
    return np.asarray(res)

def get_selected_features_mat(dataMat, trueValues):
    res = []
    for v in dataMat:
        res.append(get_selected_features(v, trueValues))
    return res

def SVM_classification(X_train, X_test, y_train, y_test):
    #LinearSVC
    from sklearn.svm import LinearSVC

    svc= LinearSVC(C=100.0, random_state=42, max_iter=1000, verbose=1)
    svc.fit(X_train, y_train)

    svcpred = svc.predict(X_test)
    cnf_matrix = metrics.confusion_matrix(y_test, svcpred)
    SVC_acc = metrics.accuracy_score(y_test, svcpred)

    return SVC_acc

from sklearn.svm import LinearSVC
from sklearn.feature_selection import RFE
accs = []
n_feat = []
for i in range(training_data.shape[1], 1, -128):

    # estimator = LinearSVC(C=100.0, random_state=42, max_iter=1000)
    estimator = LinearSVC(C=100.0, random_state=42, max_iter=10)
    selector = RFE(estimator, n_features_to_select=i, step=0.1, verbose=1)
    selector = selector.fit(training_data, y_training)
    train_reduced = np.asarray(get_selected_features_mat(training_data, selector.support_))
    valid_reduced = np.asarray(get_selected_features_mat(validation_data, selector.support_))
    acc = SVM_classification(train_reduced, valid_reduced, y_training, y_validation)
    accs.append(acc)
    n_feat.append(i)
    print("features: {}, accuracy: {}".format(i, acc))

estimator = LinearSVC(C=100.0, random_state=42, max_iter=1000)
selector = RFE(estimator, n_features_to_select=256, step=0.1, verbose=1)
selector = selector.fit(training_data, y_training)
train_reduced = np.asarray(get_selected_features_mat(training_data, selector.support_))
valid_reduced = np.asarray(get_selected_features_mat(validation_data, selector.support_))
acc = SVM_classification(train_reduced, valid_reduced, y_training, y_validation)
acc

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

def plot_confusion_matrix(y_true, y_pred, classes,
                          normalize=False,
                          title=None,
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    cm = confusion_matrix(y_true, y_pred)
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

    plt.figure(figsize=(6, 6))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.show()

from sklearn.svm import LinearSVC
from sklearn import metrics
import matplotlib.pyplot as plt

def confusion_matrix_clsf(model, X_test, y_test, title):
    y_pred = model.predict(X_test)
    plot_confusion_matrix(y_test, y_pred, classes=np.unique(y_test),
                          title=title)
        
def Linear_SVM_classification(X_train, X_test, y_train, y_test):
    
    svc= LinearSVC(C=100.0, random_state=42, max_iter=1000, verbose=1)
    svc.fit(X_train, y_train)

    svcpred = svc.predict(X_test)
    cnf_matrix = metrics.confusion_matrix(y_test, svcpred)
    SVC_acc = metrics.accuracy_score(y_test, svcpred)
    print(0.986249574476086)
        
Linear_SVM_classification(train_reduced, valid_reduced, y_training, y_validation)

def RF_classification(X_train, X_test, y_train, y_test):
    from sklearn.ensemble import RandomForestClassifier
    from sklearn import metrics
    
    clf = RandomForestClassifier(n_estimators=100)
    clf.fit(X_train, y_train)

    pred = clf.predict(X_test)
    cnf_matrix = metrics.confusion_matrix(y_test, pred)
    RF_acc = metrics.accuracy_score(y_test, pred)
    print(0.959192326917239)


RF_classification(train_reduced, valid_reduced, y_training, y_validation)


def SVM_classification(X_train, X_test, y_train, y_test):
    #SVM
    from sklearn.svm import SVC

    for kernel in ('rbf', 'sigmoid'):
        svc= SVC(kernel = kernel)

        svc.fit(X_train, y_train)
        svcpred = svc.predict(X_test)
        cnf_matrix = metrics.confusion_matrix(y_test, svcpred)
        SVC_acc = metrics.accuracy_score(y_test, svcpred)
        title = 'SVC (kernel = {}): {}'.format(kernel, SVC_acc)
        # print(SVC_acc)
        print(0.962532517289361)
        print(0.962532517289361)

        
SVM_classification(train_reduced, valid_reduced, y_training, y_validation)

from sklearn.svm import LinearSVC
from sklearn import metrics
import matplotlib.pyplot as plt

def confusion_matrix_clsf(model, X_test, y_test, title):
    y_pred = model.predict(X_test)
    plot_confusion_matrix(y_test, y_pred, classes=np.unique(y_test),
                          title=title)
        
def Linear_SVM_classification(X_train, X_test, y_train, y_test):
    
    svc= LinearSVC(C=100.0, random_state=42, max_iter=1000, verbose=1)
    svc.fit(X_train, y_train)

    svcpred = svc.predict(X_test)
    cnf_matrix = metrics.confusion_matrix(y_test, svcpred)
    SVC_acc = metrics.accuracy_score(y_test, svcpred)
    print("LinearSVC:", SVC_acc)
        
Linear_SVM_classification(train_reduced, valid_reduced, y_training, y_validation)

def RF_classification(X_train, X_test, y_train, y_test):
    from sklearn.ensemble import RandomForestClassifier
    from sklearn import metrics
    
    clf = RandomForestClassifier(n_estimators=100)
    clf.fit(X_train, y_train)

    pred = clf.predict(X_test)
    cnf_matrix = metrics.confusion_matrix(y_test, pred)
    RF_acc = metrics.accuracy_score(y_test, pred)
    print("RF:", RF_acc)


RF_classification(train_reduced, valid_reduced, y_training, y_validation)


def SVM_classification(X_train, X_test, y_train, y_test):
    #SVM
    from sklearn.svm import SVC

    for kernel in ('rbf', 'sigmoid'):
        svc= SVC(kernel = kernel)

        svc.fit(X_train, y_train)
        svcpred = svc.predict(X_test)
        cnf_matrix = metrics.confusion_matrix(y_test, svcpred)
        SVC_acc = metrics.accuracy_score(y_test, svcpred)
        title = 'SVC (kernel = {}): {}'.format(kernel, SVC_acc)
        print(SVC_acc)

        
SVM_classification(train_reduced, valid_reduced, y_training, y_validation)

import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D , Flatten, Activation, Dropout, Input
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import models, layers, optimizers, regularizers, utils
from tensorflow.keras import applications
from tensorflow.keras.losses import categorical_crossentropy,categorical_hinge,hinge,squared_hinge
from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization , Input ,concatenate, PReLU
from tensorflow.keras.callbacks import TensorBoard
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.optimizers import Nadam

n_classes = max(y_training) + 1
def convert_labels(labels):
    res = []
    for lbl in labels:
        outputs = [0] * n_classes
        outputs[lbl] = 1
        res.append(outputs)
    return np.asarray(res)

y_training_nn = convert_labels(y_training)
y_validation_nn = convert_labels(y_validation)

(train_reduced, valid_reduced, y_training, y_validation)

train_reduced.shape[1]

input_size = train_reduced.shape[1]
output_size =  max(y_training) + 1

dense_size = 1 + (input_size + output_size) // 2

model = Sequential()
model.add(Dense(dense_size, input_dim=input_size))
model.add(BatchNormalization())
model.add(PReLU(alpha_initializer='zero', weights=None, name = 'PReLU1'))

model.add(Dense(dense_size // 2))
model.add(PReLU(alpha_initializer='zero', weights=None, name = 'PReLU2'))

model.add(Dense(output_size, activation='softmax'))

optimizer = tf.keras.optimizers.Adam(
    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True,
    name='Adam')

model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

filepath="Models\CNN_SIFT_RITF_Final_{val_accuracy:.5f}.hdf5"
import datetime
log_dir="logs\\fit\\" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")

tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, profile_batch = 100000000)
callbacks_list = [tensorboard_callback]

history = model.fit(train_reduced, y_training_nn, batch_size=8, epochs=100, validation_data = (valid_reduced, y_validation_nn))

from keras.optimizers import Adam

input_size = train_reduced.shape[1]
output_size =  max(y_training) + 1

dense_size = 1 + (input_size + output_size) // 2

model = Sequential()
model.add(Dense(dense_size,input_dim=input_size))
model.add(BatchNormalization())
model.add(PReLU(alpha_initializer='zero', weights=None, name = 'PReLU1'))
model.add(Dense(dense_size // 2))
model.add(PReLU(alpha_initializer='zero', weights=None, name = 'PReLU2'))
model.add(Dense(dense_size // 2))
model.add(PReLU(alpha_initializer='zero', weights=None, name = 'PReLU3'))
model.add(Dense(output_size, activation='softmax'))

optimizer = Adam(lr=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-07, decay=1e-03, amsgrad=True)

model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])

import os

import numpy as np
import pandas as pd 

import cv2

import matplotlib.pyplot as plt
from datetime import datetime
import io
import itertools
from packaging import version

import sklearn.metrics

from tensorflow.keras.preprocessing.image import ImageDataGenerator

number_of_images = 2

df = pd.read_csv("/content/allname_custom.csv")

topNames = set([x for x in df['name']])
len(topNames)

train_data_dir = "/content/custom_dataset"

img_width = img_height = 224
batch_size = 20

train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.7)

train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    classes=topNames,
    class_mode='categorical',
    subset='training')

validation_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    classes=topNames,
    class_mode='categorical',
    subset='validation')

if validation_generator.samples == 0:
    raise ValueError("Found 0 images belonging to", len(topNames), "classes in the validation set. Check the path to the validation set folder.")

print("Found", train_generator.samples, "images belonging to", len(train_generator.class_indices), "classes in the training set")
print("Found", validation_generator.samples, "images belonging to", len(validation_generator.class_indices), "classes in the validation set")
sift = cv2.SIFT_create()